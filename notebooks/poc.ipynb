{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f9fa6a",
   "metadata": {},
   "source": [
    "**Setup & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e89e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15563508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook dir: /Users/it-by/Desktop/GitHub/textthreat-poc/notebooks\n",
      "Repo root: /Users/it-by/Desktop/GitHub/textthreat-poc\n",
      "Jigsaw train.csv: /Users/it-by/Desktop/GitHub/textthreat-poc/data/jigsaw/train.csv\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Paths (notebook is in notebooks/, repo root is parent)\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "BASE_DIR = NOTEBOOK_DIR.parent\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "JIGSAW_DIR = DATA_DIR / \"jigsaw\"\n",
    "DREDDIT_DIR = DATA_DIR / \"dreaddit\"\n",
    "EXPORT_DIR = DATA_DIR / \"exports\"\n",
    "MODEL_DIR = BASE_DIR / \"models\" / \"distilbert_jigsaw\"\n",
    "\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LABEL_COLS = [\n",
    "    \"toxic\",\n",
    "    \"severe_toxic\",\n",
    "    \"obscene\",\n",
    "    \"threat\",\n",
    "    \"insult\",\n",
    "    \"identity_hate\",\n",
    "]\n",
    "\n",
    "id2label = {i: c for i, c in enumerate(LABEL_COLS)}\n",
    "label2id = {c: i for i, c in enumerate(LABEL_COLS)}\n",
    "\n",
    "print(\"Notebook dir:\", NOTEBOOK_DIR)\n",
    "print(\"Repo root:\", BASE_DIR)\n",
    "print(\"Jigsaw train.csv:\", JIGSAW_DIR / \"train.csv\")\n",
    "print(\"Device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da1616",
   "metadata": {},
   "source": [
    "## Prepare Jigsaw Dataset for DistilBERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18b1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JIGSAW ===\n",
      "Rows: 159571\n",
      "Columns: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "\n",
      "Label distribution (sum of 1s):\n",
      "toxic            15294\n",
      "severe_toxic      1595\n",
      "obscene           8449\n",
      "threat             478\n",
      "insult            7877\n",
      "identity_hate     1405\n",
      "dtype: int64\n",
      "\n",
      "Comment length stats (chars):\n",
      "count    159571.000000\n",
      "mean        394.073221\n",
      "std         590.720282\n",
      "min           6.000000\n",
      "25%          96.000000\n",
      "50%         205.000000\n",
      "75%         435.000000\n",
      "max        5000.000000\n",
      "Name: char_len, dtype: float64\n",
      "=== DREDDIT (TRAIN) ===\n",
      "Rows: 2838\n",
      "Columns: ['subreddit', 'post_id', 'sentence_range', 'text', 'id', 'label', 'confidence', 'social_timestamp', 'social_karma', 'syntax_ari', 'lex_liwc_WC', 'lex_liwc_Analytic', 'lex_liwc_Clout', 'lex_liwc_Authentic', 'lex_liwc_Tone', 'lex_liwc_WPS', 'lex_liwc_Sixltr', 'lex_liwc_Dic', 'lex_liwc_function', 'lex_liwc_pronoun', 'lex_liwc_ppron', 'lex_liwc_i', 'lex_liwc_we', 'lex_liwc_you', 'lex_liwc_shehe', 'lex_liwc_they', 'lex_liwc_ipron', 'lex_liwc_article', 'lex_liwc_prep', 'lex_liwc_auxverb', 'lex_liwc_adverb', 'lex_liwc_conj', 'lex_liwc_negate', 'lex_liwc_verb', 'lex_liwc_adj', 'lex_liwc_compare', 'lex_liwc_interrog', 'lex_liwc_number', 'lex_liwc_quant', 'lex_liwc_affect', 'lex_liwc_posemo', 'lex_liwc_negemo', 'lex_liwc_anx', 'lex_liwc_anger', 'lex_liwc_sad', 'lex_liwc_social', 'lex_liwc_family', 'lex_liwc_friend', 'lex_liwc_female', 'lex_liwc_male', 'lex_liwc_cogproc', 'lex_liwc_insight', 'lex_liwc_cause', 'lex_liwc_discrep', 'lex_liwc_tentat', 'lex_liwc_certain', 'lex_liwc_differ', 'lex_liwc_percept', 'lex_liwc_see', 'lex_liwc_hear', 'lex_liwc_feel', 'lex_liwc_bio', 'lex_liwc_body', 'lex_liwc_health', 'lex_liwc_sexual', 'lex_liwc_ingest', 'lex_liwc_drives', 'lex_liwc_affiliation', 'lex_liwc_achieve', 'lex_liwc_power', 'lex_liwc_reward', 'lex_liwc_risk', 'lex_liwc_focuspast', 'lex_liwc_focuspresent', 'lex_liwc_focusfuture', 'lex_liwc_relativ', 'lex_liwc_motion', 'lex_liwc_space', 'lex_liwc_time', 'lex_liwc_work', 'lex_liwc_leisure', 'lex_liwc_home', 'lex_liwc_money', 'lex_liwc_relig', 'lex_liwc_death', 'lex_liwc_informal', 'lex_liwc_swear', 'lex_liwc_netspeak', 'lex_liwc_assent', 'lex_liwc_nonflu', 'lex_liwc_filler', 'lex_liwc_AllPunc', 'lex_liwc_Period', 'lex_liwc_Comma', 'lex_liwc_Colon', 'lex_liwc_SemiC', 'lex_liwc_QMark', 'lex_liwc_Exclam', 'lex_liwc_Dash', 'lex_liwc_Quote', 'lex_liwc_Apostro', 'lex_liwc_Parenth', 'lex_liwc_OtherP', 'lex_dal_max_pleasantness', 'lex_dal_max_activation', 'lex_dal_max_imagery', 'lex_dal_min_pleasantness', 'lex_dal_min_activation', 'lex_dal_min_imagery', 'lex_dal_avg_activation', 'lex_dal_avg_imagery', 'lex_dal_avg_pleasantness', 'social_upvote_ratio', 'social_num_comments', 'syntax_fk_grade', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "# --- Jigsaw EDA ---\n",
    "jigsaw_path = JIGSAW_DIR / \"train.csv\"\n",
    "jig = pd.read_csv(jigsaw_path)\n",
    "\n",
    "print(\"=== JIGSAW ===\")\n",
    "print(\"Rows:\", len(jig))\n",
    "print(\"Columns:\", jig.columns.tolist())\n",
    "\n",
    "print(\"\\nLabel distribution (sum of 1s):\")\n",
    "print(jig[LABEL_COLS].sum())\n",
    "\n",
    "jig[\"char_len\"] = jig[\"comment_text\"].str.len()\n",
    "print(\"\\nComment length stats (chars):\")\n",
    "print(jig[\"char_len\"].describe())\n",
    "\n",
    "jig[[\"id\", \"comment_text\"]].head(3)\n",
    "\n",
    "dreaddit_train_path = DREDDIT_DIR / \"dreaddit-train.csv\"\n",
    "\n",
    "if dreaddit_train_path.exists():\n",
    "    dre = pd.read_csv(dreaddit_train_path)\n",
    "    print(\"=== DREDDIT (TRAIN) ===\")\n",
    "    print(\"Rows:\", len(dre))\n",
    "    print(\"Columns:\", dre.columns.tolist())\n",
    "    dre[[\"id\", \"text\", \"label\"]].head(3)\n",
    "else:\n",
    "    print(\"Dreaddit train not found, skipping for now.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca8f4a",
   "metadata": {},
   "source": [
    "## Prepare Jigsaw Dataset for DistilBERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee1837c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 159571 examples [00:00, 171481.78 examples/s]\n",
      "Map: 100%|██████████| 18000/18000 [00:02<00:00, 7841.73 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 12098.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 18000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 2000\n",
       " }))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load via HuggingFace datasets from CSV\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\"train\": str(jigsaw_path)}\n",
    ")\n",
    "\n",
    "ds = dataset[\"train\"]\n",
    "\n",
    "# Shuffle + subset for faster PoC\n",
    "ds = ds.shuffle(seed=42).select(range(20000))  # 20k rows\n",
    "\n",
    "# Train/validation split\n",
    "split = ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = split[\"train\"]\n",
    "val_ds = split[\"test\"]\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"comment_text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=256,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "def prepare(ds_hf):\n",
    "    keep = [\"input_ids\", \"attention_mask\"] + LABEL_COLS\n",
    "    drop = [c for c in ds_hf.column_names if c not in keep]\n",
    "    ds_hf = ds_hf.remove_columns(drop)\n",
    "    ds_hf.set_format(\"torch\")\n",
    "    return ds_hf\n",
    "\n",
    "train_ds = prepare(train_ds)\n",
    "val_ds = prepare(val_ds)\n",
    "\n",
    "train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f2f2e",
   "metadata": {},
   "source": [
    "## Define DistilBERT Model & Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d6b516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model & metrics ready.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(LABEL_COLS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))  # sigmoid\n",
    "    y_true = labels\n",
    "    y_pred = (probs >= 0.5).astype(int)\n",
    "\n",
    "    f1_micro = f1_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "    try:\n",
    "        roc_macro = roc_auc_score(y_true, probs, average=\"macro\")\n",
    "    except ValueError:\n",
    "        roc_macro = float(\"nan\")\n",
    "\n",
    "    return {\"f1_micro\": f1_micro, \"roc_auc_macro\": roc_macro}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\"Model & metrics ready.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
